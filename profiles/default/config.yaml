# The networked file system can be a little slow.
# Files can take up to 30 seconds to appear.
output-wait: 30

# If a job fails, retry it a couple of times in case it's a temporary issue.
retries: 2

# Execute the workflow using Slurm jobs with no limit on the number
# of Slurm jobs created.
# Note: some rule executions will be grouped together,
# so one Slurm job may be several rule executions.
executor: slurm
jobs: unlimited

# Set the number of threads to use per job.
# For mzMine, I found that using all of the physical cores (i.e., no hyperthreading)
# provides the best performance. That is, if your system has 128 hyperthreaded
# cores, use 64 threads. To find the number you should use, run `lscpu` and
# take the number of "CPU(s)" available and divide by the "Thread(s) per core".
# When grouping jobs, this is part of how Snakemake decides how many CPUs
# to request for the entire group.
# Note: while the Slurm executor plugin's documentation says it prefers this,
# it doesn't seem to work correctly, so set the "resources.cpus_per_task" as well.
set-threads:
  all: 1
  run_msconvert: 1
  prepare_mzmine_inputs: 1
  run_mzmine: 64
  prepare_transition_list: 1
  skyline_centroided_analysis: 4

# These are the default resources for Slurm to allocate per rule execution.
# Note: when tasks are grouped together, the resources they require will be
# added together as well.
default-resources:
  slurm_partition: short-cpu
  tasks: 1
  cpus_per_task: 1
  mem_mb_per_cpu: 500
  runtime: 15     # Runtime is measured in minutes.
  slurm_extra: '"--exclusive=user"'     # Notice both the single and double quotes.

# Some rules need to override the default Slurm resources.
# Per the comment on "set-threads", if the login node has fewer cores than
# the compute node and we want to use more threads than the login node has,
# we need to set "cpus_per_task" to the number of threads we actually want.
set-resources:
  prepare_mzmine_inputs:
    slurm_partition: 'day-long-cpu'
    slurm_extra: '"--exclusive"'    # Notice both the single and double quotes.
  run_mzmine:
    slurm_partition: 'day-long-cpu'
    cpus_per_task: 64       # Slipstick and Riviera compute nodes have 64 physical cores.
    mem_mb_per_cpu: 3500    # About 500,000 MB / 128 cpus. Must use max CPU count with "--exclusive".
    runtime: 1400           # 1440 minutes = 1 day. Request slightly less.
    slurm_extra: '"--exclusive"'    # Notice both the single and double quotes.
  skyline_centroided_analysis:
    slurm_partition: 'day-long-cpu'
    cpus_per_task: 4
    mem_mb_per_cpu: 3500
    slurm_extra: '"--exclusive"'
  skyline_tof_profile_analysis:
    slurm_partition: 'day-long-cpu'
    cpus_per_task: 4
    mem_mb_per_cpu: 3500
    slurm_extra: '"--exclusive"'

# Group the execution of some rules together so they are all submitted
# as the same Slurm job. This will reduce the total number of jobs submitted
# so it doesn't overload the scheduler.
# Note: Snakemake will use the threads per "set-threads" to determine how many
# threads are allocated, not "resources.cpus_per_task" unfortunately.
groups:
- run_msconvert=msconvert_group
- prepare_mzmine_inputs=mzmine_group
- run_mzmine=mzmine_group

group-components:
- msconvert_group=10
